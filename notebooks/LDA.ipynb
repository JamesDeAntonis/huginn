{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, spacy, gensim\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rec.autos' 'comp.sys.mac.hardware' 'comp.graphics' 'sci.space'\n",
      " 'talk.politics.guns' 'sci.med' 'comp.sys.ibm.pc.hardware'\n",
      " 'comp.os.ms-windows.misc' 'rec.motorcycles' 'talk.religion.misc'\n",
      " 'misc.forsale' 'alt.atheism' 'sci.electronics' 'comp.windows.x'\n",
      " 'rec.sport.hockey' 'rec.sport.baseball' 'soc.religion.christian'\n",
      " 'talk.politics.mideast' 'talk.politics.misc' 'sci.crypt']\n"
     ]
    }
   ],
   "source": [
    "# Import Dataset\n",
    "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
    "print(df.target_names.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...</td>\n",
       "      <td>16</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>From: bmdelane@quads.uchicago.edu (brian manni...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...</td>\n",
       "      <td>2</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>From: irwin@cmptrc.lonestar.org (Irwin Arnstei...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>From: david@terminus.ericsson.se (David Bold)\\...</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: ...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>From: dbm0000@tm0006.lerc.nasa.gov (David B. M...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nS...</td>\n",
       "      <td>6</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  target  \\\n",
       "0   From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n",
       "1   From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n",
       "2   From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4   \n",
       "3   From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1   \n",
       "4   From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14   \n",
       "5   From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...      16   \n",
       "6   From: bmdelane@quads.uchicago.edu (brian manni...      13   \n",
       "7   From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...       3   \n",
       "8   From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...       2   \n",
       "9   From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...       4   \n",
       "10  From: irwin@cmptrc.lonestar.org (Irwin Arnstei...       8   \n",
       "11  From: david@terminus.ericsson.se (David Bold)\\...      19   \n",
       "12  From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: ...       4   \n",
       "13  From: dbm0000@tm0006.lerc.nasa.gov (David B. M...      14   \n",
       "14  From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nS...       6   \n",
       "\n",
       "                target_names  \n",
       "0                  rec.autos  \n",
       "1      comp.sys.mac.hardware  \n",
       "2      comp.sys.mac.hardware  \n",
       "3              comp.graphics  \n",
       "4                  sci.space  \n",
       "5         talk.politics.guns  \n",
       "6                    sci.med  \n",
       "7   comp.sys.ibm.pc.hardware  \n",
       "8    comp.os.ms-windows.misc  \n",
       "9      comp.sys.mac.hardware  \n",
       "10           rec.motorcycles  \n",
       "11        talk.religion.misc  \n",
       "12     comp.sys.mac.hardware  \n",
       "13                 sci.space  \n",
       "14              misc.forsale  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From: (wheres my thing) Subject: WHAT car is this!? Nntp-Posting-Host: '\n",
      " 'rac3.wam.umd.edu Organization: University of Maryland, College Park Lines: '\n",
      " '15 I was wondering if anyone out there could enlighten me on this car I saw '\n",
      " 'the other day. It was a 2-door sports car, looked to be from the late 60s/ '\n",
      " 'early 70s. It was called a Bricklin. The doors were really small. In '\n",
      " 'addition, the front bumper was separate from the rest of the body. This is '\n",
      " 'all I know. If anyone can tellme a model name, engine specs, years of '\n",
      " 'production, where this car is made, history, or whatever info you have on '\n",
      " 'this funky looking car, please e-mail. Thanks, - IL ---- brought to you by '\n",
      " 'your neighborhood Lerxst ---- ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: DeprecationWarning: invalid escape sequence \\S\n",
      "<>:5: DeprecationWarning: invalid escape sequence \\s\n",
      "<>:3: DeprecationWarning: invalid escape sequence \\S\n",
      "<>:5: DeprecationWarning: invalid escape sequence \\s\n",
      "<>:3: DeprecationWarning: invalid escape sequence \\S\n",
      "<>:5: DeprecationWarning: invalid escape sequence \\s\n",
      "<ipython-input-4-23aa64077bc2>:3: DeprecationWarning: invalid escape sequence \\S\n",
      "  data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
      "<ipython-input-4-23aa64077bc2>:5: DeprecationWarning: invalid escape sequence \\s\n",
      "  data = [re.sub('\\s+', ' ', sent) for sent in data]\n"
     ]
    }
   ],
   "source": [
    "data = df.content.values.tolist()[0:100]\n",
    "# Remove Emails\n",
    "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "pprint(data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp', 'posting', 'host', 'rac', 'wam', 'umd', 'edu', 'organization', 'university', 'of', 'maryland', 'college', 'park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['where s thing subject car nntp post host line wonder out could enlighten car see other day door sport car look late early call door really small addition front bumper separate rest body know can tellme model name engine specs year production where car make history info funky look car mail thank bring neighborhood lerxst', 'poll final call summary final call clock report acceleration post fair number brave soul upgrade si clock oscillator share experience poll send brief message detail experience procedure top speed attain cpu rate speed add card adapter heat sink hour usage day floppy disk functionality floppy especially request will summarize next day so add network knowledge base do clock upgrade answer poll thank']\n"
     ]
    }
   ],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
    "    return texts_out\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# Run in terminal: python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only Noun, Adj, Verb, Adverb\n",
    "data_lemmatized = lemmatization(data_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word',       \n",
    "                             min_df=10,                        # minimum reqd occurences of a word \n",
    "                             stop_words='english',             # remove stop words\n",
    "                             lowercase=True,                   # convert all words to lowercase\n",
    "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
    "                             # max_features=50000,             # max number of uniq words\n",
    "                            )\n",
    "\n",
    "data_vectorized = vectorizer.fit_transform(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsicity:  17.50588235294118 %\n"
     ]
    }
   ],
   "source": [
    "# Materialize the sparse data\n",
    "data_dense = data_vectorized.todense()\n",
    "# Compute Sparsicity = Percentage of Non-Zero cells\n",
    "print(\"Sparsicity: \", ((data_dense > 0).sum()/data_dense.size)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
      "                          evaluate_every=-1, learning_decay=0.7,\n",
      "                          learning_method='online', learning_offset=10.0,\n",
      "                          max_doc_update_iter=100, max_iter=10,\n",
      "                          mean_change_tol=0.001, n_components=20, n_jobs=-1,\n",
      "                          perp_tol=0.1, random_state=100, topic_word_prior=None,\n",
      "                          total_samples=1000000.0, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# Build LDA Model\n",
    "lda_model = LatentDirichletAllocation(n_components=20,               # Number of topics\n",
    "                                      max_iter=10,               # Max learning iterations\n",
    "                                      learning_method='online',   \n",
    "                                      random_state=100,          # Random state\n",
    "                                      batch_size=128,            # n docs in each learning iter\n",
    "                                      evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
    "                                      n_jobs = -1,               # Use all available CPUs\n",
    "                                     )\n",
    "lda_output = lda_model.fit_transform(data_vectorized)\n",
    "\n",
    "print(lda_model)  # Model attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood:  -11037.304305704733\n",
      "Perplexity:  184.67242798696623\n",
      "{'batch_size': 128,\n",
      " 'doc_topic_prior': None,\n",
      " 'evaluate_every': -1,\n",
      " 'learning_decay': 0.7,\n",
      " 'learning_method': 'online',\n",
      " 'learning_offset': 10.0,\n",
      " 'max_doc_update_iter': 100,\n",
      " 'max_iter': 10,\n",
      " 'mean_change_tol': 0.001,\n",
      " 'n_components': 20,\n",
      " 'n_jobs': -1,\n",
      " 'perp_tol': 0.1,\n",
      " 'random_state': 100,\n",
      " 'topic_word_prior': None,\n",
      " 'total_samples': 1000000.0,\n",
      " 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda_model.score(data_vectorized))\n",
    "\n",
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda_model.perplexity(data_vectorized))\n",
    "\n",
    "# See model parameters\n",
    "pprint(lda_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LatentDirichletAllocation(batch_size=128,\n",
       "                                                 doc_topic_prior=None,\n",
       "                                                 evaluate_every=-1,\n",
       "                                                 learning_decay=0.7,\n",
       "                                                 learning_method='batch',\n",
       "                                                 learning_offset=10.0,\n",
       "                                                 max_doc_update_iter=100,\n",
       "                                                 max_iter=10,\n",
       "                                                 mean_change_tol=0.001,\n",
       "                                                 n_components=10, n_jobs=None,\n",
       "                                                 perp_tol=0.1,\n",
       "                                                 random_state=None,\n",
       "                                                 topic_word_prior=None,\n",
       "                                                 total_samples=1000000.0,\n",
       "                                                 verbose=0),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'learning_decay': [0.5], 'n_components': [10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Search Param\n",
    "search_params = {'n_components': [10], 'learning_decay': [.5]}\n",
    "\n",
    "# Init the Model\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "# Init Grid Search Class\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "model.fit(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.5, 'n_components': 10}\n",
      "Best Log Likelihood Score:  -2741.314174249789\n",
      "Model Perplexity:  96.22924732197038\n"
     ]
    }
   ],
   "source": [
    "# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>Topic7</th>\n",
       "      <th>Topic8</th>\n",
       "      <th>Topic9</th>\n",
       "      <th>dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.39</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc95</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc96</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc97</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc98</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.70</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc99</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Topic0  Topic1  Topic2  Topic3  Topic4  Topic5  Topic6  Topic7  Topic8  \\\n",
       "Doc0     0.01    0.01    0.01    0.01    0.01    0.01    0.21    0.01    0.75   \n",
       "Doc1     0.01    0.01    0.01    0.48    0.01    0.01    0.42    0.01    0.01   \n",
       "Doc2     0.00    0.00    0.00    0.00    0.17    0.00    0.00    0.00    0.42   \n",
       "Doc3     0.01    0.01    0.01    0.14    0.01    0.01    0.01    0.01    0.01   \n",
       "Doc4     0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "Doc95    0.93    0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.01   \n",
       "Doc96    0.00    0.00    0.00    0.00    0.00    0.00    0.97    0.00    0.00   \n",
       "Doc97    0.30    0.01    0.01    0.01    0.01    0.49    0.01    0.01    0.17   \n",
       "Doc98    0.02    0.02    0.02    0.02    0.02    0.02    0.16    0.02    0.02   \n",
       "Doc99    0.01    0.01    0.91    0.01    0.01    0.01    0.01    0.01    0.01   \n",
       "\n",
       "       Topic9  dominant_topic  \n",
       "Doc0     0.01               8  \n",
       "Doc1     0.01               3  \n",
       "Doc2     0.39               8  \n",
       "Doc3     0.82               9  \n",
       "Doc4     0.96               9  \n",
       "...       ...             ...  \n",
       "Doc95    0.01               0  \n",
       "Doc96    0.00               6  \n",
       "Doc97    0.01               5  \n",
       "Doc98    0.70               9  \n",
       "Doc99    0.01               2  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Document - Topic Matrix\n",
    "lda_output = best_lda_model.transform(data_vectorized)\n",
    "\n",
    "# column names\n",
    "topicnames = [\"Topic\" + str(i) for i in range(best_lda_model.n_components)]\n",
    "\n",
    "# index names\n",
    "docnames = [\"Doc\" + str(i) for i in range(len(data))]\n",
    "\n",
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(lda_output, columns=topicnames, index=docnames)\n",
    "\n",
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "\n",
    "df_document_topic.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic Num</th>\n",
       "      <th>Num Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic Num  Num Documents\n",
       "0          8             23\n",
       "1          5             18\n",
       "2          9             16\n",
       "3          4             11\n",
       "4          0             10\n",
       "5          1              8\n",
       "6          6              6\n",
       "7          3              4\n",
       "8          7              2\n",
       "9          2              2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_distribution = df_document_topic['dominant_topic'].value_counts().reset_index(name=\"Num Documents\")\n",
    "df_topic_distribution.columns = ['Topic Num', 'Num Documents']\n",
    "df_topic_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el72649940038569701691125\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el72649940038569701691125_data = {\"mdsDat\": {\"x\": [32.42095184326172, 0.648955225944519, 71.01968383789062, 3.7859814167022705, -42.666500091552734, -3.6216893196105957, -3.632401704788208, -36.58440017700195, 44.391380310058594, 40.235809326171875], \"y\": [8.115229606628418, 71.70709991455078, 9.971006393432617, 33.18513488769531, -9.22206974029541, -43.52651596069336, -4.171707630157471, 35.804412841796875, 50.61538314819336, -31.591665267944336], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [26.002691036781577, 16.127955104160435, 15.987633627850329, 13.185283364749711, 11.753670504322471, 7.869765248582991, 3.080773346201156, 2.9394804529666168, 1.9886697998736749, 1.0640775145110364]}, \"tinfo\": {\"Term\": [\"thing\", \"use\", \"people\", \"post\", \"year\", \"know\", \"line\", \"problem\", \"possible\", \"information\", \"write\", \"car\", \"thank\", \"nntp\", \"distribution\", \"day\", \"file\", \"come\", \"say\", \"good\", \"include\", \"old\", \"ask\", \"article\", \"subject\", \"think\", \"great\", \"note\", \"host\", \"reply\", \"agree\", \"long\", \"people\", \"control\", \"sure\", \"hand\", \"leave\", \"let\", \"follow\", \"want\", \"right\", \"set\", \"file\", \"way\", \"require\", \"mean\", \"case\", \"day\", \"write\", \"time\", \"point\", \"probably\", \"place\", \"try\", \"say\", \"work\", \"real\", \"article\", \"organization\", \"turn\", \"post\", \"make\", \"think\", \"line\", \"just\", \"use\", \"subject\", \"know\", \"reply\", \"year\", \"window\", \"help\", \"email\", \"run\", \"available\", \"need\", \"summary\", \"look\", \"tell\", \"use\", \"host\", \"nntp\", \"car\", \"number\", \"thank\", \"good\", \"organization\", \"really\", \"probably\", \"distribution\", \"buy\", \"know\", \"subject\", \"ask\", \"close\", \"line\", \"leave\", \"computer\", \"turn\", \"just\", \"work\", \"post\", \"write\", \"come\", \"think\", \"way\", \"make\", \"question\", \"really\", \"tell\", \"mean\", \"article\", \"man\", \"think\", \"require\", \"know\", \"set\", \"point\", \"real\", \"say\", \"look\", \"time\", \"hand\", \"write\", \"end\", \"come\", \"opinion\", \"course\", \"thing\", \"subject\", \"nntp\", \"follow\", \"line\", \"memory\", \"case\", \"hard\", \"want\", \"people\", \"good\", \"buy\", \"post\", \"right\", \"make\", \"day\", \"year\", \"car\", \"summary\", \"end\", \"close\", \"include\", \"service\", \"ask\", \"base\", \"buy\", \"old\", \"new\", \"place\", \"major\", \"turn\", \"man\", \"make\", \"note\", \"fact\", \"help\", \"question\", \"good\", \"number\", \"long\", \"bad\", \"thing\", \"come\", \"require\", \"distribution\", \"set\", \"time\", \"use\", \"say\", \"post\", \"line\", \"think\", \"problem\", \"bit\", \"memory\", \"computer\", \"bad\", \"try\", \"information\", \"opinion\", \"email\", \"thank\", \"work\", \"run\", \"sure\", \"hard\", \"place\", \"file\", \"fact\", \"use\", \"follow\", \"major\", \"say\", \"want\", \"window\", \"number\", \"line\", \"reply\", \"make\", \"think\", \"just\", \"time\", \"subject\", \"write\", \"know\", \"host\", \"note\", \"fact\", \"course\", \"world\", \"service\", \"reply\", \"available\", \"nntp\", \"file\", \"real\", \"right\", \"let\", \"subject\", \"need\", \"distribution\", \"come\", \"great\", \"opinion\", \"post\", \"just\", \"buy\", \"work\", \"end\", \"want\", \"bit\", \"article\", \"line\", \"probably\", \"tell\", \"write\", \"look\", \"know\", \"think\", \"use\", \"way\", \"note\", \"hard\", \"organization\", \"nntp\", \"include\", \"case\", \"end\", \"available\", \"reply\", \"post\", \"old\", \"new\", \"tell\", \"thank\", \"bit\", \"memory\", \"line\", \"host\", \"let\", \"point\", \"hand\", \"know\", \"help\", \"good\", \"make\", \"subject\", \"use\", \"write\", \"say\", \"probably\", \"question\", \"possible\", \"information\", \"thank\", \"day\", \"distribution\", \"major\", \"include\", \"organization\", \"turn\", \"nntp\", \"post\", \"host\", \"need\", \"just\", \"subject\", \"time\", \"article\", \"car\", \"year\", \"know\", \"write\", \"probably\", \"place\", \"hard\", \"sure\", \"set\", \"note\", \"tell\", \"service\", \"agree\", \"right\", \"world\", \"summary\", \"reply\", \"long\", \"number\", \"base\", \"question\", \"use\", \"thing\", \"great\", \"service\", \"turn\", \"mean\", \"leave\", \"base\", \"man\", \"course\", \"possible\", \"point\", \"new\", \"people\", \"say\", \"time\", \"think\", \"post\", \"write\", \"article\", \"use\", \"probably\", \"major\", \"place\", \"hard\", \"sure\", \"set\", \"note\", \"organization\", \"tell\", \"agree\", \"bad\", \"line\", \"distribution\", \"thank\", \"good\", \"subject\", \"summary\", \"reply\", \"include\", \"file\", \"old\", \"ask\", \"distribution\", \"good\", \"know\", \"come\", \"thing\", \"use\", \"post\", \"write\", \"line\", \"probably\", \"major\", \"place\", \"hard\", \"sure\", \"set\", \"note\", \"organization\", \"tell\", \"service\", \"turn\", \"agree\", \"real\", \"email\", \"summary\", \"control\", \"fact\", \"thank\", \"subject\", \"reply\", \"base\", \"course\", \"follow\", \"just\", \"way\", \"look\", \"case\", \"right\", \"work\", \"want\", \"day\"], \"Freq\": [35.0, 83.0, 60.0, 68.0, 56.0, 52.0, 92.0, 27.0, 18.0, 20.0, 79.0, 37.0, 24.0, 26.0, 21.0, 25.0, 18.0, 27.0, 47.0, 23.0, 17.0, 18.0, 18.0, 51.0, 51.0, 59.0, 17.0, 12.0, 16.0, 25.0, 11.676572712365699, 10.250101687150053, 42.913925749465136, 9.199252523867786, 7.773146774948711, 11.676624274681888, 10.29939789955901, 10.94720449661655, 7.816594290664169, 11.32789917215287, 10.967662233549923, 5.406904736475599, 8.393000285408473, 12.131791535576541, 5.774766339193039, 5.848492512060698, 5.567239817603359, 10.03562763623627, 29.921456469048913, 12.408361100085333, 6.85155084871998, 3.9174414727558804, 3.8960610053232005, 9.047779672966167, 17.009507262354177, 8.7781808068851, 4.258532739357455, 16.763607255530598, 3.9565012124444663, 3.9778437575315526, 18.57925304737886, 10.061559871434277, 15.314117288678341, 21.098245060965386, 9.044625206559708, 16.824141159006125, 10.452730898456728, 9.248843938949612, 6.505445910529584, 7.183930418189601, 14.360991334280852, 13.74208077030408, 7.75008195434446, 12.392884211065457, 8.327877903811526, 9.954534932868262, 5.67229413182764, 9.9057652622357, 4.610833633036066, 30.908156993565488, 6.207651682962183, 8.89046161554739, 12.07003263919995, 7.822903370440013, 7.595786596151039, 7.306790283787691, 3.711104370148257, 6.615353325093737, 2.623759806287457, 5.068131319512183, 5.3704072102054345, 11.77978658146865, 11.148139131827667, 3.6396176362720043, 3.581130236292168, 18.073108860595752, 3.1583291549032855, 2.809747900746096, 2.2647482379663058, 5.713056226841429, 4.636824439047391, 11.993847164821304, 8.258004133867159, 4.1861823498439, 5.4468447236106075, 3.9690166775607656, 3.949493811069321, 10.360480954842366, 12.622760311646914, 5.048478794870547, 5.942426736607053, 20.543650632382533, 6.613244270895998, 21.537303622111832, 4.96091808215764, 18.552196058599034, 3.9166771184609126, 6.038354807646991, 4.05854394317237, 13.826436009508837, 6.917749772227107, 9.55105169775917, 5.0484399524065235, 20.627048762119117, 4.051327400986588, 6.874704063407598, 3.276890719857629, 4.057735864571785, 8.012760327457956, 11.09163964957341, 5.364848316192941, 3.0686779870594325, 18.08108365132207, 2.9542795359744294, 2.608444006426871, 2.078778648993226, 4.1727176493000995, 10.18341675398239, 4.198991133962238, 4.05854720931363, 8.439962543230804, 3.894579908631678, 4.4330673806807, 3.9630639612329777, 43.119147409977906, 23.631894886945755, 6.927522287735104, 7.908627124174529, 8.17824761000439, 7.103215452986069, 5.12249075173184, 7.249714693061171, 6.389319437622811, 9.25792300069242, 6.910498124548251, 7.35248671878964, 3.4740861632395674, 3.4430680217899057, 3.651459773278287, 4.66038226827504, 9.144309460643633, 3.024642436735451, 3.2188195477709107, 4.314701749852065, 3.754413954668859, 4.7285726517028825, 4.66705533342247, 2.5154995158136293, 2.847268670879444, 6.063360741474248, 4.705866981810379, 2.2482623946812734, 3.564885362734986, 1.6979785958148266, 3.9367009189511104, 8.052448355680236, 4.706398167988865, 4.923876194475949, 4.278254389858071, 3.6801169145134955, 26.201783036722492, 9.799647206558681, 10.517913493504212, 7.532914236956266, 7.3714570415416265, 11.166283763153817, 6.864670024346494, 3.88734169808699, 3.7376363851049477, 6.880795621924399, 7.111328731367111, 6.135673760034692, 3.040768829412259, 2.997259942973286, 2.6125251500988975, 4.353413368609419, 3.0578420061084763, 18.419345014376077, 2.997273749704322, 2.0304022413217466, 8.979223248040547, 4.360956703419803, 3.5579440308885997, 4.323890207401946, 14.588651408645049, 3.6145980239551783, 4.997667453391213, 8.056804828158237, 3.9626683870232253, 3.5811191479397984, 5.449415748636684, 7.605050514368265, 3.715584561937912, 8.004447006782375, 4.829781026554537, 5.115858241405433, 5.741977880869475, 6.445999858391669, 3.7406801533887117, 6.124257826474242, 3.692055957015527, 5.774594465586506, 3.8827350607676387, 2.4831440500776267, 4.430624021676184, 3.31056525270247, 9.31745547489126, 3.8926241789258293, 3.6847143664896884, 4.2566323972296845, 2.5192169239677606, 1.8152872355195728, 8.783826790358178, 3.882810669405437, 2.93577313627416, 3.1428397032460227, 1.980149857138482, 2.7800048580491405, 1.6893348874155591, 5.738532455156693, 10.00244382689764, 1.041720247117897, 1.175806667313016, 5.551407455187328, 2.020987531925504, 3.414258165373609, 3.143907903451657, 3.2738596335780636, 2.1286972719593376, 3.763347325152784, 1.9276097085323656, 1.927598569384231, 3.7619424764777025, 2.2290014705730803, 1.7918541371105263, 1.92757031377469, 1.9275711288578303, 2.809028087789556, 6.426731586138656, 1.5097109549900516, 1.7464126647937017, 1.0096795232960813, 1.927579781580409, 1.0096707579901083, 1.009673239815644, 5.599198879120211, 1.0096593877595768, 1.0096701218419162, 1.0096742932672782, 1.0096636888918988, 2.845439507972879, 1.0096697676853696, 1.0096418527267033, 1.4324971613421762, 1.9275606876255695, 2.5125465334989556, 1.9275774951696212, 1.0096542868746798, 0.09178797244472567, 0.09249565395438888, 11.054503095962685, 7.432699552327677, 4.577361479977442, 4.401757103034898, 3.016999895684254, 1.4055665192575837, 1.5078393199722941, 1.0421277248205625, 1.042120708485414, 2.174517179228602, 5.134145987983733, 1.1105044318312791, 1.3524075828385054, 1.7869288952317928, 1.989527029999841, 1.0421122667570164, 1.5328334399901533, 1.0420673518225039, 1.2531317990095685, 1.0971694714389646, 1.1098428932085644, 0.09473739404050101, 0.09473739335039266, 0.09473739422058848, 0.09473739353175975, 0.09473739392962424, 0.09475822263976424, 0.09473739387908242, 0.09474447182638386, 0.09473739331992342, 0.09480937422289519, 0.09480198491222447, 0.09479188082107073, 0.0947869208418235, 0.0947822932762356, 0.09477938188540194, 0.0947772162421694, 0.09477066151557326, 0.09476939318600419, 8.888018009799852, 2.0588312477311574, 1.0784250670991602, 1.0784232189455267, 1.0784177094576264, 1.0784122340391766, 1.0784382175598102, 1.0784280921064957, 1.0784359681349736, 1.0784053910232143, 1.0784260928453389, 1.0784215793914111, 3.039197243143741, 1.7211515097482277, 1.0784262511576066, 1.7563373289247575, 2.0147456757872306, 1.7686945275886876, 1.0784233935138823, 1.4998498511969631, 0.09803579720473822, 0.09803579697144457, 0.09803579611255438, 0.09803579748831162, 0.0980357963994172, 0.0980357970281613, 0.09803579603406049, 0.0980357977625519, 0.09803579694714523, 0.09803579606578987, 0.09814107786896915, 0.09806137737497606, 0.09803579815470635, 0.09803579808018979, 0.09803579802282503, 0.09803579800326251, 0.09803579787905399, 0.09803579756278155, 1.053438816105221, 1.0534492638179045, 1.0534385228970182, 1.0534455325276664, 1.053487161573235, 1.0534931471381082, 2.011217917729972, 1.0534387855740734, 1.0534174583124178, 2.0111462607068495, 1.0534123516728748, 1.0534629533941156, 1.0534523260154238, 0.09576304143471127, 0.09576304100975147, 0.09576303946435173, 0.0957630419420778, 0.09576303998094138, 0.09576304111444432, 0.09576303932479092, 0.09576304243491841, 0.09576304097127511, 0.09576304079919923, 0.09576304060082734, 0.09576303937999735, 0.09576303991217947, 0.09576304009786135, 0.09576304264800745, 0.09576304048553526, 0.09576304013033053, 0.09576304300857276, 0.09576304287084553, 0.09576304207641052, 0.09576304186424965, 0.09576304177752758, 0.0957630416840879, 0.09576304167487815, 0.09576304156039687, 0.09576304155547803, 0.09576304154034894, 0.09576304152028904, 0.09576304151406034, 0.09576304144717776, 0.09576304143601055], \"Total\": [35.0, 83.0, 60.0, 68.0, 56.0, 52.0, 92.0, 27.0, 18.0, 20.0, 79.0, 37.0, 24.0, 26.0, 21.0, 25.0, 18.0, 27.0, 47.0, 23.0, 17.0, 18.0, 18.0, 51.0, 51.0, 59.0, 17.0, 12.0, 16.0, 25.0, 12.537887101681143, 13.52940602408434, 60.00209771493584, 13.42573436071449, 11.578498236231882, 18.40523414458846, 16.32571387099938, 18.23594988164744, 15.495117150954293, 23.212531573087233, 23.143203341624083, 11.68638905772753, 18.256736132049856, 26.95080037417912, 13.648693117561923, 14.632242210469538, 14.376438574654387, 25.98945816733522, 79.1613349945622, 33.04663861858074, 18.340170588250203, 10.537298335181216, 10.64969093654361, 25.19244709837533, 47.667699983824484, 25.849599224857222, 12.60451075165475, 51.567164384823954, 12.317023047800994, 12.49259413771326, 68.72780461010011, 35.67700289767021, 59.217721016899226, 92.967251787781, 31.658207264008, 83.69525819456733, 51.66785135768377, 52.860109004013125, 25.757971124900795, 56.496195627181095, 19.726043234530337, 19.74190111434326, 13.231536219165813, 22.70028091473172, 16.917659659200822, 21.72021302161859, 13.367192942137482, 23.888445470016734, 12.424113643923818, 83.69525819456733, 16.915848824506796, 26.478592992907792, 37.41648998904274, 24.90678964448138, 24.599097436210982, 23.927070957281753, 12.317023047800994, 23.232858879020185, 10.537298335181216, 21.964194214146648, 24.06839182178049, 52.860109004013125, 51.66785135768377, 18.290341972083787, 18.31596640512807, 92.967251787781, 16.32571387099938, 15.326613875051045, 12.49259413771326, 31.658207264008, 25.849599224857222, 68.72780461010011, 79.1613349945622, 27.95796451688029, 59.217721016899226, 26.95080037417912, 35.67700289767021, 17.616640565489234, 23.232858879020185, 12.424113643923818, 14.632242210469538, 51.567164384823954, 16.61511078487185, 59.217721016899226, 13.648693117561923, 52.860109004013125, 11.68638905772753, 18.340170588250203, 12.60451075165475, 47.667699983824484, 23.888445470016734, 33.04663861858074, 18.40523414458846, 79.1613349945622, 16.45246295383894, 27.95796451688029, 13.568590042115789, 17.39228251980063, 35.01567629145204, 51.66785135768377, 26.478592992907792, 15.495117150954293, 92.967251787781, 15.465630633669113, 14.376438574654387, 11.544612598224925, 23.212531573087233, 60.00209771493584, 23.927070957281753, 24.06839182178049, 68.72780461010011, 23.143203341624083, 35.67700289767021, 25.98945816733522, 56.496195627181095, 37.41648998904274, 13.367192942137482, 16.45246295383894, 18.31596640512807, 17.24323824592987, 12.468873368364601, 18.290341972083787, 16.427370645284654, 24.06839182178049, 18.287639359295706, 21.181744373386913, 10.64969093654361, 10.62383691262205, 12.49259413771326, 16.61511078487185, 35.67700289767021, 12.291505917662768, 13.447388808354942, 19.74190111434326, 17.616640565489234, 23.927070957281753, 24.90678964448138, 13.52940602408434, 15.51961837358265, 35.01567629145204, 27.95796451688029, 13.648693117561923, 21.964194214146648, 11.68638905772753, 33.04663861858074, 83.69525819456733, 47.667699983824484, 68.72780461010011, 92.967251787781, 59.217721016899226, 27.06288738700571, 14.409011920635335, 15.465630633669113, 15.326613875051045, 15.51961837358265, 25.19244709837533, 20.073235855935156, 13.568590042115789, 13.231536219165813, 24.599097436210982, 25.849599224857222, 22.70028091473172, 11.578498236231882, 11.544612598224925, 10.64969093654361, 18.256736132049856, 13.447388808354942, 83.69525819456733, 15.495117150954293, 10.62383691262205, 47.667699983824484, 23.212531573087233, 19.726043234530337, 24.90678964448138, 92.967251787781, 25.757971124900795, 35.67700289767021, 59.217721016899226, 31.658207264008, 33.04663861858074, 51.66785135768377, 79.1613349945622, 52.860109004013125, 16.915848824506796, 12.291505917662768, 13.447388808354942, 17.39228251980063, 20.17072042418068, 12.468873368364601, 25.757971124900795, 16.917659659200822, 26.478592992907792, 18.256736132049856, 12.60451075165475, 23.143203341624083, 18.23594988164744, 51.66785135768377, 21.72021302161859, 21.964194214146648, 27.95796451688029, 17.32936824851284, 13.568590042115789, 68.72780461010011, 31.658207264008, 24.06839182178049, 25.849599224857222, 16.45246295383894, 23.212531573087233, 14.409011920635335, 51.567164384823954, 92.967251787781, 10.537298335181216, 12.424113643923818, 79.1613349945622, 23.888445470016734, 52.860109004013125, 59.217721016899226, 83.69525819456733, 26.95080037417912, 12.291505917662768, 11.544612598224925, 12.317023047800994, 26.478592992907792, 17.24323824592987, 14.376438574654387, 16.45246295383894, 16.917659659200822, 25.757971124900795, 68.72780461010011, 18.287639359295706, 21.181744373386913, 12.424113643923818, 24.599097436210982, 14.409011920635335, 15.465630633669113, 92.967251787781, 16.915848824506796, 18.23594988164744, 18.340170588250203, 18.40523414458846, 52.860109004013125, 19.74190111434326, 23.927070957281753, 35.67700289767021, 51.66785135768377, 83.69525819456733, 79.1613349945622, 47.667699983824484, 10.537298335181216, 17.616640565489234, 18.09127000009444, 20.073235855935156, 24.599097436210982, 25.98945816733522, 21.964194214146648, 10.62383691262205, 17.24323824592987, 12.317023047800994, 12.49259413771326, 26.478592992907792, 68.72780461010011, 16.915848824506796, 21.72021302161859, 31.658207264008, 51.66785135768377, 33.04663861858074, 51.567164384823954, 37.41648998904274, 56.496195627181095, 52.860109004013125, 79.1613349945622, 10.537298335181216, 10.64969093654361, 11.544612598224925, 11.578498236231882, 11.68638905772753, 12.291505917662768, 12.424113643923818, 12.468873368364601, 12.537887101681143, 23.143203341624083, 20.17072042418068, 13.367192942137482, 25.757971124900795, 13.52940602408434, 24.90678964448138, 16.427370645284654, 17.616640565489234, 83.69525819456733, 35.01567629145204, 17.32936824851284, 12.468873368364601, 12.49259413771326, 14.632242210469538, 16.32571387099938, 16.427370645284654, 16.61511078487185, 17.39228251980063, 18.09127000009444, 18.340170588250203, 21.181744373386913, 60.00209771493584, 47.667699983824484, 33.04663861858074, 59.217721016899226, 68.72780461010011, 79.1613349945622, 51.567164384823954, 83.69525819456733, 10.537298335181216, 10.62383691262205, 10.64969093654361, 11.544612598224925, 11.578498236231882, 11.68638905772753, 12.291505917662768, 12.317023047800994, 12.424113643923818, 12.537887101681143, 15.51961837358265, 92.967251787781, 21.964194214146648, 24.599097436210982, 23.927070957281753, 51.66785135768377, 13.367192942137482, 25.757971124900795, 17.24323824592987, 18.256736132049856, 18.287639359295706, 18.290341972083787, 21.964194214146648, 23.927070957281753, 52.860109004013125, 27.95796451688029, 35.01567629145204, 83.69525819456733, 68.72780461010011, 79.1613349945622, 92.967251787781, 10.537298335181216, 10.62383691262205, 10.64969093654361, 11.544612598224925, 11.578498236231882, 11.68638905772753, 12.291505917662768, 12.317023047800994, 12.424113643923818, 12.468873368364601, 12.49259413771326, 12.537887101681143, 12.60451075165475, 13.231536219165813, 13.367192942137482, 13.42573436071449, 13.447388808354942, 24.599097436210982, 51.66785135768377, 25.757971124900795, 16.427370645284654, 17.39228251980063, 15.495117150954293, 31.658207264008, 26.95080037417912, 23.888445470016734, 14.376438574654387, 23.143203341624083, 25.849599224857222, 23.212531573087233, 25.98945816733522], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.8523, -3.9826, -2.5506, -4.0907, -4.2592, -3.8523, -3.9778, -3.9168, -4.2536, -3.8826, -3.9149, -4.6222, -4.1824, -3.814, -4.5563, -4.5437, -4.5929, -4.0037, -2.9113, -3.7915, -4.3854, -4.9444, -4.9499, -4.1073, -3.4761, -4.1376, -4.8609, -3.4906, -4.9345, -4.9291, -3.3878, -4.0011, -3.5811, -3.2607, -4.1077, -3.487, -3.963, -4.0853, -4.4372, -4.338, -3.1677, -3.2117, -3.7845, -3.3151, -3.7126, -3.5342, -4.0966, -3.5391, -4.3038, -2.4012, -4.0064, -3.6472, -3.3415, -3.7751, -3.8046, -3.8434, -4.5209, -3.9428, -4.8676, -4.2092, -4.1513, -3.3658, -3.4209, -4.5403, -4.5565, -2.9378, -4.6822, -4.7991, -5.0147, -4.0894, -4.2982, -3.3478, -3.721, -4.4004, -4.1372, -4.4537, -4.4586, -3.4855, -3.288, -4.2044, -4.0413, -2.8009, -3.9344, -2.7537, -4.2219, -2.9029, -4.4582, -4.0253, -4.4226, -3.1969, -3.8894, -3.5668, -4.2044, -2.7969, -4.4244, -3.8956, -4.6366, -4.4228, -3.7424, -3.4173, -4.1436, -4.7022, -2.9286, -4.7402, -4.8647, -5.0917, -4.3949, -3.5027, -4.3886, -4.4226, -3.6905, -4.4639, -4.3344, -4.4464, -1.8668, -2.4681, -3.6952, -3.5628, -3.5293, -3.6702, -3.9971, -3.6498, -3.7761, -3.4053, -3.6977, -3.6357, -4.3854, -4.3944, -4.3356, -4.0916, -3.4176, -4.5239, -4.4617, -4.1687, -4.3078, -4.0771, -4.0902, -4.7083, -4.5844, -3.8285, -4.0819, -4.8206, -4.3596, -5.1013, -4.2604, -3.5448, -4.0818, -4.0366, -4.1772, -4.3278, -2.25, -3.2335, -3.1627, -3.4965, -3.5182, -3.1029, -3.5894, -4.1581, -4.1974, -3.5871, -3.5541, -3.7017, -4.4037, -4.4181, -4.5555, -4.0448, -4.3981, -2.6024, -4.4181, -4.8076, -3.3209, -4.0431, -4.2466, -4.0516, -2.8356, -4.2308, -3.9068, -3.4293, -4.1389, -4.2401, -3.8203, -3.487, -4.2033, -3.0347, -3.5399, -3.4823, -3.3669, -3.2512, -3.7954, -3.3024, -3.8085, -3.3612, -3.7581, -4.2051, -3.6261, -3.9175, -2.8828, -3.7556, -3.8105, -3.6662, -4.1907, -4.5184, -2.9418, -3.7581, -4.0377, -3.9695, -4.4315, -4.0922, -4.5903, -3.3675, -2.8118, -5.0738, -4.9527, -3.4006, -4.4111, -3.8867, -3.9692, -3.9287, -4.3592, -2.8515, -3.5205, -3.5205, -2.8519, -3.3753, -3.5936, -3.5206, -3.5206, -3.144, -2.3164, -3.7649, -3.6193, -4.1672, -3.5206, -4.1672, -4.1672, -2.4542, -4.1672, -4.1672, -4.1672, -4.1672, -3.1311, -4.1672, -4.1672, -3.8174, -3.5206, -3.2555, -3.5206, -4.1672, -6.5651, -6.5574, -1.727, -2.124, -2.6088, -2.6479, -3.0256, -3.7894, -3.7192, -4.0886, -4.0886, -3.3531, -2.494, -4.0251, -3.828, -3.5494, -3.442, -4.0886, -3.7028, -4.0887, -3.9042, -4.0371, -4.0257, -6.4865, -6.4865, -6.4865, -6.4865, -6.4865, -6.4863, -6.4865, -6.4864, -6.4865, -6.4858, -6.4858, -6.4859, -6.486, -6.486, -6.4861, -6.4861, -6.4862, -6.4862, -1.5544, -3.017, -3.6636, -3.6636, -3.6636, -3.6636, -3.6636, -3.6636, -3.6636, -3.6636, -3.6636, -3.6636, -2.6275, -3.1961, -3.6636, -3.1759, -3.0386, -3.1689, -3.6636, -3.3337, -6.0615, -6.0615, -6.0615, -6.0615, -6.0615, -6.0615, -6.0615, -6.0615, -6.0615, -6.0615, -6.0605, -6.0613, -6.0615, -6.0615, -6.0615, -6.0615, -6.0615, -6.0615, -3.0617, -3.0617, -3.0617, -3.0617, -3.0616, -3.0616, -2.415, -3.0617, -3.0617, -2.415, -3.0617, -3.0617, -3.0617, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596, -5.4596], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2758, 1.0694, 1.0118, 0.9689, 0.9485, 0.8919, 0.8863, 0.8367, 0.6627, 0.6295, 0.6002, 0.5762, 0.5698, 0.5488, 0.4868, 0.4299, 0.3983, 0.3954, 0.3741, 0.3674, 0.3624, 0.3575, 0.3414, 0.3229, 0.3165, 0.2669, 0.2618, 0.2233, 0.2113, 0.2026, 0.0389, 0.0812, -0.0055, -0.1361, 0.0941, -0.2574, -0.251, -0.3962, -0.0291, -0.7154, 1.5072, 1.4623, 1.2897, 1.2194, 1.1159, 1.0444, 0.9674, 0.9443, 0.8334, 0.8285, 0.8221, 0.7333, 0.6932, 0.6665, 0.6495, 0.6384, 0.625, 0.5684, 0.4343, 0.3582, 0.3246, 0.3234, 0.2911, 0.2101, 0.1925, 0.1868, 0.1819, 0.1281, 0.1169, 0.1124, 0.1064, 0.0789, -0.4357, -0.0743, -0.5616, -0.0909, -0.3763, 1.3025, 1.2233, 0.9328, 0.9322, 0.913, 0.9121, 0.8219, 0.8213, 0.7863, 0.7402, 0.7224, 0.7001, 0.5957, 0.5941, 0.5921, 0.5398, 0.4885, 0.4319, 0.4305, 0.4125, 0.378, 0.3586, 0.2947, 0.2369, 0.2141, 0.196, 0.178, 0.1265, 0.1189, 0.1172, 0.0597, 0.0932, 0.0533, -0.2638, 0.0512, -0.2521, -0.0473, 1.7559, 1.5666, 1.3688, 1.2935, 1.2198, 1.1392, 1.1365, 1.1007, 1.0817, 1.0706, 1.0529, 0.968, 0.9059, 0.8993, 0.7961, 0.7549, 0.6647, 0.624, 0.5963, 0.5054, 0.4802, 0.4047, 0.3515, 0.3437, 0.3303, 0.2725, 0.2442, 0.2226, 0.2078, 0.0971, -0.1015, -0.3151, -0.2893, -0.61, -1.0526, -0.7522, 2.1087, 1.7555, 1.7555, 1.4307, 1.3965, 1.3274, 1.068, 0.891, 0.8769, 0.867, 0.8504, 0.8327, 0.804, 0.7925, 0.7358, 0.7074, 0.6599, 0.6272, 0.4982, 0.4861, 0.4717, 0.469, 0.4282, 0.39, 0.289, 0.1772, 0.1755, 0.1463, 0.0629, -0.0812, -0.1083, -0.2017, -0.5141, 1.7939, 1.608, 1.5757, 1.4339, 1.4014, 1.3382, 1.1057, 1.02, 1.0193, 0.9941, 0.9176, 0.889, 0.8359, 0.8292, 0.823, 0.7569, 0.6599, 0.6137, 0.5306, 0.4849, 0.4437, 0.4382, 0.435, 0.4248, 0.4199, 0.3986, 0.3465, 0.3127, 0.2281, 0.1845, -0.1153, 0.0723, -0.1975, -0.3936, -0.6991, 0.0036, 2.2964, 1.6901, 1.6253, 1.5286, 1.4341, 1.3976, 1.3358, 1.3079, 1.2641, 1.1103, 0.9857, 0.9844, 0.97, 0.9335, 0.8218, 0.751, 0.6704, 0.6614, 0.5862, 0.5805, 0.577, 0.5581, 0.5069, 0.3146, 0.2649, 0.1914, -0.0259, -0.2352, -0.3747, -1.2632, -1.7694, 3.0343, 2.5334, 1.8454, 1.7513, 1.5418, 1.5043, 1.0902, 1.0572, 1.0431, 1.0274, 0.9327, 0.8035, 0.7506, 0.6524, 0.27, 0.0703, 0.0112, -0.054, -0.2816, -0.348, -0.7403, -1.1846, -1.1952, -1.2759, -1.2789, -1.2881, -1.3384, -1.3493, -1.3529, -1.3585, -1.9707, -1.8333, -1.4219, -2.0779, -1.4341, -2.0444, -1.6282, -1.6982, -3.2566, 2.5466, 1.7874, 1.47, 1.4681, 1.31, 1.2005, 1.1943, 1.1829, 1.1372, 1.0978, 1.0841, 0.9401, 0.9349, 0.5964, 0.4953, 0.3997, 0.388, 0.1165, 0.0503, -0.1041, -0.7596, -0.7678, -0.7702, -0.8509, -0.8539, -0.8631, -0.9136, -0.9157, -0.9244, -0.9335, -1.1457, -2.9367, -1.4941, -1.6074, -1.5797, -2.3496, -0.9975, -1.6535, 1.7477, 1.6906, 1.6889, 1.6888, 1.5058, 1.4202, 1.2742, 1.2644, 1.0393, 0.8146, 0.3649, 0.2237, 0.0629, -0.1577, -0.1659, -0.1683, -0.249, -0.252, -0.2612, -0.3117, -0.3138, -0.3225, -0.3261, -0.328, -0.3316, -0.3369, -0.3854, -0.3956, -0.4, -0.4016, -1.0055, -1.7477, -1.0516, -0.6018, -0.6588, -0.5433, -1.2578, -1.0968, -0.9762, -0.4684, -0.9445, -1.0551, -0.9475, -1.0605]}, \"token.table\": {\"Topic\": [1, 1, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 6, 10, 2, 3, 5, 6, 7, 1, 3, 4, 5, 1, 2, 3, 4, 5, 9, 1, 5, 6, 7, 2, 3, 4, 5, 6, 2, 4, 8, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 6, 10, 1, 2, 5, 6, 1, 2, 5, 1, 3, 4, 6, 9, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 6, 8, 10, 2, 4, 5, 3, 4, 6, 7, 1, 4, 5, 6, 1, 5, 6, 10, 1, 3, 5, 6, 1, 2, 3, 4, 6, 7, 10, 1, 2, 3, 4, 6, 9, 1, 3, 7, 1, 3, 4, 5, 7, 2, 4, 7, 2, 6, 7, 8, 1, 2, 4, 6, 7, 8, 10, 1, 2, 4, 5, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 5, 6, 7, 8, 10, 1, 2, 3, 9, 1, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 10, 1, 4, 1, 2, 3, 5, 6, 1, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 1, 3, 4, 9, 1, 3, 5, 9, 3, 5, 7, 1, 2, 6, 8, 1, 2, 3, 4, 7, 9, 2, 3, 6, 7, 8, 4, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 7, 10, 1, 3, 4, 5, 6, 1, 2, 3, 7, 8, 1, 2, 3, 9, 1, 4, 5, 1, 2, 3, 7, 9, 2, 3, 4, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 5, 1, 2, 3, 4, 1, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 5, 1, 3, 4, 5, 7, 9, 2, 4, 6, 9, 1, 3, 4, 1, 2, 3, 5, 6, 7, 8, 2, 4, 1, 5, 2, 3, 6, 7, 1, 2, 5, 6, 7, 8, 1, 2, 3, 4, 5, 9, 10, 1, 2, 3, 4, 5, 6, 9, 1, 2, 3, 4, 5, 8, 9, 1, 3, 4, 5, 1, 2, 4, 8, 9, 1, 2, 4, 5, 6, 7, 9, 10, 1, 3, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 5, 1, 2, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 5, 8], \"Freq\": [0.9570990632377747, 0.3296671477441766, 0.4072358883898652, 0.05817655548426646, 0.05817655548426646, 0.11635311096853292, 0.038784370322844305, 0.019392185161422153, 0.1640209901257639, 0.21869465350101855, 0.10934732675050927, 0.38271564362678245, 0.05467366337525464, 0.05467366337525464, 0.47287864640598365, 0.059109830800747956, 0.059109830800747956, 0.23643932320299182, 0.11821966160149591, 0.19330372228137851, 0.12886914818758569, 0.19330372228137851, 0.45104201865654986, 0.18262204370856672, 0.18262204370856672, 0.12174802913904448, 0.36524408741713343, 0.06087401456952224, 0.06087401456952224, 0.06940101136066706, 0.6940101136066706, 0.13880202272133413, 0.06940101136066706, 0.20774134130038932, 0.16619307304031145, 0.3739344143407008, 0.08309653652015572, 0.1246448047802336, 0.32071420925677824, 0.6414284185135565, 0.02672618410473152, 0.41734953819355375, 0.13911651273118458, 0.20867476909677687, 0.06955825636559229, 0.06955825636559229, 0.13911651273118458, 0.27298586868995944, 0.21838869495196758, 0.054597173737991896, 0.43677738990393516, 0.21460789809563413, 0.1430719320637561, 0.25037588111157316, 0.1788399150796951, 0.1430719320637561, 0.035767983015939024, 0.19573795128247196, 0.19573795128247196, 0.5219678700865918, 0.06524598376082398, 0.6703543924074064, 0.14896764275720142, 0.07448382137860071, 0.22998706440319786, 0.22998706440319786, 0.11499353220159893, 0.3449805966047968, 0.057496766100799464, 0.3847713921396204, 0.11543141764188612, 0.15390855685584817, 0.07695427842792409, 0.11543141764188612, 0.15390855685584817, 0.13658593485153972, 0.2276432247525662, 0.09105728990102649, 0.18211457980205298, 0.18211457980205298, 0.13658593485153972, 0.045528644950513245, 0.6046161131624339, 0.07557701414530424, 0.30230805658121696, 0.24312469271153467, 0.48624938542306934, 0.12156234635576733, 0.12156234635576733, 0.07436387943053258, 0.22309163829159773, 0.22309163829159773, 0.3718193971526629, 0.43819442545132326, 0.21909721272566163, 0.21909721272566163, 0.05477430318141541, 0.5162916757623421, 0.19360937841087827, 0.19360937841087827, 0.06453645947029277, 0.16717466200277536, 0.2925556585048569, 0.16717466200277536, 0.20896832750346922, 0.04179366550069384, 0.04179366550069384, 0.04179366550069384, 0.28852754054834556, 0.17311652432900732, 0.17311652432900732, 0.11541101621933822, 0.17311652432900732, 0.11541101621933822, 0.6519884455546718, 0.2716618523144466, 0.05433237046288932, 0.2598614699692282, 0.17324097997948548, 0.08662048998974274, 0.2598614699692282, 0.17324097997948548, 0.7091515613877963, 0.20261473182508466, 0.050653682956271165, 0.35469695090367054, 0.4729292678715607, 0.05911615848394509, 0.05911615848394509, 0.17398124164456907, 0.05799374721485635, 0.4059562305039945, 0.05799374721485635, 0.1159874944297127, 0.1159874944297127, 0.05799374721485635, 0.09963515670088885, 0.09963515670088885, 0.049817578350444425, 0.348723048453111, 0.348723048453111, 0.2842864703280921, 0.1895243135520614, 0.12634954236804094, 0.0947621567760307, 0.12634954236804094, 0.12634954236804094, 0.06317477118402047, 0.1702607158701985, 0.22701428782693134, 0.35943928905930794, 0.07567142927564377, 0.056753571956732835, 0.056753571956732835, 0.018917857318910943, 0.037835714637821885, 0.6125306420911718, 0.18375919262735155, 0.06125306420911718, 0.06125306420911718, 0.6032041144766657, 0.05483673767969688, 0.05483673767969688, 0.16451021303909064, 0.05483673767969688, 0.2258859931445247, 0.19361656555244974, 0.19361656555244974, 0.04302590345609995, 0.16134713796037478, 0.10756475864024986, 0.06453885518414991, 0.010756475864024987, 0.7391307484008185, 0.22173922452024555, 0.12558372639883203, 0.4186124213294401, 0.29302869493060807, 0.04186124213294401, 0.08372248426588802, 0.2823838529030634, 0.2823838529030634, 0.18825590193537559, 0.09412795096768779, 0.2802926027357815, 0.11211704109431259, 0.11211704109431259, 0.25226334246220333, 0.14014630136789075, 0.028029260273578147, 0.028029260273578147, 0.180558531257674, 0.42130323960123933, 0.3009308854294567, 0.06018617708589133, 0.41005335434557877, 0.41005335434557877, 0.06834222572426313, 0.06834222572426313, 0.19397851087099646, 0.7112545398603204, 0.06465950362366549, 0.27624038466050366, 0.46040064110083945, 0.18416025644033576, 0.04604006411008394, 0.23605232467454762, 0.14163139480472858, 0.09442092986981905, 0.3304732545443667, 0.09442092986981905, 0.047210464934909525, 0.3398972144181007, 0.18883178578783374, 0.2265981429454005, 0.151065428630267, 0.0755327143151335, 0.24407098854250486, 0.40678498090417475, 0.3254279847233398, 0.20074847346325322, 0.32119755754120516, 0.08029938938530129, 0.20074847346325322, 0.16059877877060258, 0.2734087162244083, 0.05468174324488166, 0.05468174324488166, 0.3827722027141716, 0.05468174324488166, 0.10936348648976332, 0.05468174324488166, 0.22109887546813975, 0.22109887546813975, 0.07369962515604658, 0.29479850062418633, 0.14739925031209317, 0.3247537967962263, 0.3247537967962263, 0.08118844919905657, 0.16237689839811315, 0.08118844919905657, 0.7166416115031318, 0.04999825196533477, 0.16666083988444924, 0.04999825196533477, 0.37559775432302, 0.281698315742265, 0.281698315742265, 0.38167583918137676, 0.16357535964916145, 0.3271507192983229, 0.05452511988305382, 0.05452511988305382, 0.16582583754398333, 0.05527527918132778, 0.05527527918132778, 0.6080280709946055, 0.05527527918132778, 0.27645288697622383, 0.17460182335340452, 0.11640121556893634, 0.07275075973058522, 0.014550151946117043, 0.1309513675150534, 0.08730091167670226, 0.07275075973058522, 0.029100303892234086, 0.014550151946117043, 0.37960394332246167, 0.28470295749184626, 0.09490098583061542, 0.09490098583061542, 0.09490098583061542, 0.9607252776909512, 0.11352902345739933, 0.05676451172869967, 0.5676451172869967, 0.22705804691479867, 0.3173467085562897, 0.3173467085562897, 0.07933667713907243, 0.15867335427814486, 0.08608497173828429, 0.30129740108399505, 0.5595523162988479, 0.043042485869142146, 0.2717605344790897, 0.11646880049103846, 0.07764586699402563, 0.03882293349701282, 0.15529173398805127, 0.23293760098207691, 0.11646880049103846, 0.4396025281189548, 0.366335440099129, 0.1465341760396516, 0.47530153184179175, 0.04320923016743561, 0.17283692066974243, 0.04320923016743561, 0.04320923016743561, 0.17283692066974243, 0.17620927313741452, 0.5286278194122436, 0.2643139097061218, 0.3566356255025681, 0.29369992688446783, 0.10489283103016708, 0.18880709585430075, 0.020978566206033417, 0.04195713241206683, 0.16039941548161837, 0.4009985387040459, 0.32079883096323675, 0.08019970774080919, 0.42784815526005365, 0.3422785242080429, 0.17113926210402144, 0.1935439492301019, 0.2128983441531121, 0.2128983441531121, 0.09677197461505095, 0.1741895543070917, 0.03870878984602038, 0.03870878984602038, 0.44886013286201354, 0.5236701550056825, 0.6909358914065463, 0.25910095927745486, 0.40244319581262994, 0.40244319581262994, 0.08048863916252598, 0.08048863916252598, 0.04065189800532904, 0.32521518404263233, 0.2845632860373033, 0.08130379601065808, 0.08130379601065808, 0.2032594900266452, 0.17135182396761844, 0.08567591198380922, 0.22846909862349124, 0.17135182396761844, 0.028558637327936405, 0.25702773595142764, 0.028558637327936405, 0.2533025544113625, 0.08443418480378749, 0.371510413136665, 0.06754734784303, 0.13509469568606, 0.0506605108822725, 0.033773673921515, 0.36312316476426454, 0.030260263730355376, 0.3026026373035538, 0.1210410549214215, 0.1210410549214215, 0.030260263730355376, 0.030260263730355376, 0.35724993149158635, 0.11908331049719545, 0.03969443683239848, 0.4366388051563833, 0.32018970246736844, 0.16009485123368422, 0.32018970246736844, 0.08004742561684211, 0.08004742561684211, 0.20311783925058102, 0.3703913539275301, 0.09558486552968518, 0.21506594744179167, 0.035844324573631944, 0.035844324573631944, 0.011948108191210647, 0.023896216382421294, 0.4738819617914263, 0.17232071337870047, 0.17232071337870047, 0.12924053503402536, 0.44525579327495207, 0.14841859775831737, 0.14841859775831737, 0.11131394831873802, 0.07420929887915868, 0.07420929887915868, 0.05069440374385397, 0.7097216524139556, 0.20277761497541588, 0.3481678737728945, 0.19342659654049693, 0.07737063861619876, 0.2707972351566957, 0.11605595792429815, 0.24788405643687347, 0.09915362257474938, 0.19830724514949877, 0.09915362257474938, 0.2974608677242482, 0.37897289127401373, 0.10105943767307034, 0.26528102389180963, 0.012632429709133792, 0.10105943767307034, 0.07579457825480275, 0.025264859418267584, 0.012632429709133792, 0.025264859418267584, 0.012632429709133792, 0.12390214814096621, 0.053100920631842664, 0.7611131957230782, 0.01770030687728089, 0.01770030687728089], \"Term\": [\"agree\", \"article\", \"article\", \"article\", \"article\", \"article\", \"article\", \"article\", \"ask\", \"ask\", \"ask\", \"ask\", \"ask\", \"ask\", \"available\", \"available\", \"available\", \"available\", \"available\", \"bad\", \"bad\", \"bad\", \"bad\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"bit\", \"bit\", \"bit\", \"bit\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"car\", \"car\", \"car\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"close\", \"close\", \"close\", \"close\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"computer\", \"computer\", \"computer\", \"computer\", \"control\", \"control\", \"control\", \"course\", \"course\", \"course\", \"course\", \"course\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"email\", \"email\", \"email\", \"end\", \"end\", \"end\", \"end\", \"fact\", \"fact\", \"fact\", \"fact\", \"file\", \"file\", \"file\", \"file\", \"follow\", \"follow\", \"follow\", \"follow\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"hand\", \"hand\", \"hand\", \"hard\", \"hard\", \"hard\", \"hard\", \"hard\", \"help\", \"help\", \"help\", \"host\", \"host\", \"host\", \"host\", \"include\", \"include\", \"include\", \"include\", \"include\", \"include\", \"include\", \"information\", \"information\", \"information\", \"information\", \"information\", \"just\", \"just\", \"just\", \"just\", \"just\", \"just\", \"just\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"leave\", \"leave\", \"leave\", \"leave\", \"let\", \"let\", \"let\", \"let\", \"let\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"long\", \"long\", \"look\", \"look\", \"look\", \"look\", \"look\", \"major\", \"major\", \"major\", \"major\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"man\", \"man\", \"man\", \"man\", \"mean\", \"mean\", \"mean\", \"mean\", \"memory\", \"memory\", \"memory\", \"need\", \"need\", \"need\", \"need\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"nntp\", \"nntp\", \"nntp\", \"nntp\", \"nntp\", \"note\", \"note\", \"note\", \"number\", \"number\", \"number\", \"number\", \"number\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"organization\", \"organization\", \"organization\", \"organization\", \"organization\", \"people\", \"people\", \"people\", \"people\", \"place\", \"place\", \"place\", \"point\", \"point\", \"point\", \"point\", \"point\", \"possible\", \"possible\", \"possible\", \"possible\", \"possible\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"probably\", \"probably\", \"probably\", \"probably\", \"probably\", \"problem\", \"question\", \"question\", \"question\", \"question\", \"real\", \"real\", \"real\", \"real\", \"really\", \"really\", \"really\", \"really\", \"reply\", \"reply\", \"reply\", \"reply\", \"reply\", \"reply\", \"reply\", \"require\", \"require\", \"require\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"run\", \"run\", \"run\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"service\", \"service\", \"service\", \"service\", \"set\", \"set\", \"set\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"summary\", \"summary\", \"sure\", \"sure\", \"tell\", \"tell\", \"tell\", \"tell\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"try\", \"try\", \"try\", \"try\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"want\", \"want\", \"want\", \"want\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"window\", \"window\", \"window\", \"work\", \"work\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"world\", \"world\", \"write\", \"write\", \"write\", \"write\", \"write\", \"write\", \"write\", \"write\", \"write\", \"write\", \"year\", \"year\", \"year\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [6, 9, 10, 7, 5, 1, 2, 4, 8, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el72649940038569701691125\", ldavis_el72649940038569701691125_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el72649940038569701691125\", ldavis_el72649940038569701691125_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el72649940038569701691125\", ldavis_el72649940038569701691125_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=               x          y  topics  cluster       Freq\n",
       "topic                                                  \n",
       "5      32.420952   8.115230       1        1  26.002691\n",
       "8       0.648955  71.707100       2        1  16.127955\n",
       "9      71.019684   9.971006       3        1  15.987634\n",
       "6       3.785981  33.185135       4        1  13.185283\n",
       "4     -42.666500  -9.222070       5        1  11.753671\n",
       "0      -3.621689 -43.526516       6        1   7.869765\n",
       "1      -3.632402  -4.171708       7        1   3.080773\n",
       "3     -36.584400  35.804413       8        1   2.939480\n",
       "7      44.391380  50.615383       9        1   1.988670\n",
       "2      40.235809 -31.591665      10        1   1.064078, topic_info=      Term       Freq      Total Category  logprob  loglift\n",
       "72   thing  35.000000  35.000000  Default  30.0000  30.0000\n",
       "77     use  83.000000  83.000000  Default  29.0000  29.0000\n",
       "50  people  60.000000  60.000000  Default  28.0000  28.0000\n",
       "54    post  68.000000  68.000000  Default  27.0000  27.0000\n",
       "84    year  56.000000  56.000000  Default  26.0000  26.0000\n",
       "..     ...        ...        ...      ...      ...      ...\n",
       "9     case   0.095763  14.376439  Topic10  -5.4596  -0.4684\n",
       "62   right   0.095763  23.143203  Topic10  -5.4596  -0.9445\n",
       "81    work   0.095763  25.849599  Topic10  -5.4596  -1.0551\n",
       "78    want   0.095763  23.212532  Topic10  -5.4596  -0.9475\n",
       "15     day   0.095763  25.989458  Topic10  -5.4596  -1.0605\n",
       "\n",
       "[401 rows x 6 columns], token_table=      Topic      Freq     Term\n",
       "term                          \n",
       "0         1  0.957099    agree\n",
       "1         1  0.329667  article\n",
       "1         3  0.407236  article\n",
       "1         4  0.058177  article\n",
       "1         5  0.058177  article\n",
       "...     ...       ...      ...\n",
       "84        1  0.123902     year\n",
       "84        3  0.053101     year\n",
       "84        4  0.761113     year\n",
       "84        5  0.017700     year\n",
       "84        8  0.017700     year\n",
       "\n",
       "[416 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[6, 9, 10, 7, 5, 1, 2, 4, 8, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "panel = pyLDAvis.sklearn.prepare(best_lda_model, data_vectorized, vectorizer, mds='tsne')\n",
    "panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agree</th>\n",
       "      <th>article</th>\n",
       "      <th>ask</th>\n",
       "      <th>available</th>\n",
       "      <th>bad</th>\n",
       "      <th>base</th>\n",
       "      <th>bit</th>\n",
       "      <th>buy</th>\n",
       "      <th>car</th>\n",
       "      <th>case</th>\n",
       "      <th>...</th>\n",
       "      <th>try</th>\n",
       "      <th>turn</th>\n",
       "      <th>use</th>\n",
       "      <th>want</th>\n",
       "      <th>way</th>\n",
       "      <th>window</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>write</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic0</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>6.059567</td>\n",
       "      <td>1.099965</td>\n",
       "      <td>3.898603</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.783842</td>\n",
       "      <td>3.100011</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.099993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100011</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>3.457011</td>\n",
       "      <td>2.935529</td>\n",
       "      <td>2.247784</td>\n",
       "      <td>0.100004</td>\n",
       "      <td>3.318662</td>\n",
       "      <td>6.806613</td>\n",
       "      <td>5.861974</td>\n",
       "      <td>0.100007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100029</td>\n",
       "      <td>2.100026</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.100003</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.952167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>2.737337</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.100033</td>\n",
       "      <td>0.100005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.100054</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>2.100128</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.100073</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.617981</td>\n",
       "      <td>0.100008</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100042</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.099954</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.10001</td>\n",
       "      <td>0.100034</td>\n",
       "      <td>0.100024</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100068</td>\n",
       "      <td>1.171494</td>\n",
       "      <td>1.322743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>0.100003</td>\n",
       "      <td>3.071548</td>\n",
       "      <td>0.100010</td>\n",
       "      <td>1.412283</td>\n",
       "      <td>7.624149</td>\n",
       "      <td>1.099992</td>\n",
       "      <td>10.135576</td>\n",
       "      <td>2.036387</td>\n",
       "      <td>0.100004</td>\n",
       "      <td>0.100002</td>\n",
       "      <td>...</td>\n",
       "      <td>11.549061</td>\n",
       "      <td>0.10003</td>\n",
       "      <td>19.050755</td>\n",
       "      <td>4.510449</td>\n",
       "      <td>2.018247</td>\n",
       "      <td>3.679909</td>\n",
       "      <td>7.355103</td>\n",
       "      <td>0.100007</td>\n",
       "      <td>7.865750</td>\n",
       "      <td>1.197521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           agree   article       ask  available       bad      base  \\\n",
       "Topic0  0.100000  6.059567  1.099965   3.898603  0.100000  0.100000   \n",
       "Topic1  0.100000  0.100000  0.100029   2.100026  0.100000  0.100000   \n",
       "Topic2  0.100000  0.100000  1.100054   0.100000  0.100000  0.100000   \n",
       "Topic3  0.100000  1.617981  0.100008   0.100000  0.100000  0.100042   \n",
       "Topic4  0.100003  3.071548  0.100010   1.412283  7.624149  1.099992   \n",
       "\n",
       "              bit       buy       car      case  ...        try     turn  \\\n",
       "Topic0   1.783842  3.100011  0.100000  1.099993  ...   0.100011  0.10000   \n",
       "Topic1   1.100003  0.100000  0.100000  1.952167  ...   0.100000  0.10000   \n",
       "Topic2   0.100000  0.100000  0.100000  0.100000  ...   0.100000  0.10000   \n",
       "Topic3   0.100000  0.100000  1.099954  0.100000  ...   0.100000  1.10001   \n",
       "Topic4  10.135576  2.036387  0.100004  0.100002  ...  11.549061  0.10003   \n",
       "\n",
       "              use      want       way    window      work     world     write  \\\n",
       "Topic0   3.457011  2.935529  2.247784  0.100004  3.318662  6.806613  5.861974   \n",
       "Topic1   2.737337  0.100000  0.100000  0.100000  0.100000  0.100000  2.100033   \n",
       "Topic2   2.100128  0.100000  0.100000  0.100000  0.100000  0.100000  1.100073   \n",
       "Topic3   0.100034  0.100024  0.100000  0.100000  0.100000  0.100068  1.171494   \n",
       "Topic4  19.050755  4.510449  2.018247  3.679909  7.355103  0.100007  7.865750   \n",
       "\n",
       "            year  \n",
       "Topic0  0.100007  \n",
       "Topic1  0.100005  \n",
       "Topic2  0.100000  \n",
       "Topic3  1.322743  \n",
       "Topic4  1.197521  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic-Keyword Matrix\n",
    "df_topic_keywords = pd.DataFrame(best_lda_model.components_)\n",
    "\n",
    "# Assign Column and Index\n",
    "df_topic_keywords.columns = vectorizer.get_feature_names()\n",
    "df_topic_keywords.index = topicnames\n",
    "\n",
    "# View\n",
    "df_topic_keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic0    175.757110\n",
       "Topic1     70.987903\n",
       "Topic2     23.500966\n",
       "Topic3     65.623520\n",
       "Topic4    257.111731\n",
       "Topic5    569.897505\n",
       "Topic6    285.811639\n",
       "Topic7     42.903070\n",
       "Topic8    366.815847\n",
       "Topic9    341.590708\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_keywords.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>Word 10</th>\n",
       "      <th>Word 11</th>\n",
       "      <th>Word 12</th>\n",
       "      <th>Word 13</th>\n",
       "      <th>Word 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>line</td>\n",
       "      <td>subject</td>\n",
       "      <td>post</td>\n",
       "      <td>host</td>\n",
       "      <td>world</td>\n",
       "      <td>reply</td>\n",
       "      <td>nntp</td>\n",
       "      <td>course</td>\n",
       "      <td>article</td>\n",
       "      <td>write</td>\n",
       "      <td>fact</td>\n",
       "      <td>note</td>\n",
       "      <td>right</td>\n",
       "      <td>come</td>\n",
       "      <td>need</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>post</td>\n",
       "      <td>line</td>\n",
       "      <td>note</td>\n",
       "      <td>nntp</td>\n",
       "      <td>know</td>\n",
       "      <td>reply</td>\n",
       "      <td>use</td>\n",
       "      <td>include</td>\n",
       "      <td>hard</td>\n",
       "      <td>organization</td>\n",
       "      <td>thank</td>\n",
       "      <td>write</td>\n",
       "      <td>available</td>\n",
       "      <td>end</td>\n",
       "      <td>subject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>know</td>\n",
       "      <td>use</td>\n",
       "      <td>good</td>\n",
       "      <td>distribution</td>\n",
       "      <td>write</td>\n",
       "      <td>line</td>\n",
       "      <td>file</td>\n",
       "      <td>ask</td>\n",
       "      <td>include</td>\n",
       "      <td>come</td>\n",
       "      <td>old</td>\n",
       "      <td>thing</td>\n",
       "      <td>post</td>\n",
       "      <td>thank</td>\n",
       "      <td>subject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>possible</td>\n",
       "      <td>information</td>\n",
       "      <td>post</td>\n",
       "      <td>thank</td>\n",
       "      <td>day</td>\n",
       "      <td>distribution</td>\n",
       "      <td>nntp</td>\n",
       "      <td>subject</td>\n",
       "      <td>just</td>\n",
       "      <td>article</td>\n",
       "      <td>include</td>\n",
       "      <td>major</td>\n",
       "      <td>need</td>\n",
       "      <td>year</td>\n",
       "      <td>host</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>problem</td>\n",
       "      <td>use</td>\n",
       "      <td>line</td>\n",
       "      <td>try</td>\n",
       "      <td>memory</td>\n",
       "      <td>bit</td>\n",
       "      <td>say</td>\n",
       "      <td>think</td>\n",
       "      <td>write</td>\n",
       "      <td>computer</td>\n",
       "      <td>bad</td>\n",
       "      <td>work</td>\n",
       "      <td>thank</td>\n",
       "      <td>information</td>\n",
       "      <td>run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 5</th>\n",
       "      <td>people</td>\n",
       "      <td>write</td>\n",
       "      <td>line</td>\n",
       "      <td>post</td>\n",
       "      <td>say</td>\n",
       "      <td>use</td>\n",
       "      <td>article</td>\n",
       "      <td>think</td>\n",
       "      <td>time</td>\n",
       "      <td>way</td>\n",
       "      <td>hand</td>\n",
       "      <td>agree</td>\n",
       "      <td>want</td>\n",
       "      <td>right</td>\n",
       "      <td>let</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 6</th>\n",
       "      <td>year</td>\n",
       "      <td>car</td>\n",
       "      <td>buy</td>\n",
       "      <td>make</td>\n",
       "      <td>close</td>\n",
       "      <td>use</td>\n",
       "      <td>end</td>\n",
       "      <td>new</td>\n",
       "      <td>ask</td>\n",
       "      <td>include</td>\n",
       "      <td>summary</td>\n",
       "      <td>old</td>\n",
       "      <td>base</td>\n",
       "      <td>thing</td>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 7</th>\n",
       "      <td>thing</td>\n",
       "      <td>people</td>\n",
       "      <td>great</td>\n",
       "      <td>post</td>\n",
       "      <td>write</td>\n",
       "      <td>think</td>\n",
       "      <td>say</td>\n",
       "      <td>use</td>\n",
       "      <td>base</td>\n",
       "      <td>course</td>\n",
       "      <td>man</td>\n",
       "      <td>time</td>\n",
       "      <td>point</td>\n",
       "      <td>service</td>\n",
       "      <td>article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 8</th>\n",
       "      <td>use</td>\n",
       "      <td>line</td>\n",
       "      <td>window</td>\n",
       "      <td>help</td>\n",
       "      <td>run</td>\n",
       "      <td>car</td>\n",
       "      <td>post</td>\n",
       "      <td>know</td>\n",
       "      <td>subject</td>\n",
       "      <td>need</td>\n",
       "      <td>look</td>\n",
       "      <td>nntp</td>\n",
       "      <td>available</td>\n",
       "      <td>write</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 9</th>\n",
       "      <td>think</td>\n",
       "      <td>write</td>\n",
       "      <td>article</td>\n",
       "      <td>know</td>\n",
       "      <td>line</td>\n",
       "      <td>say</td>\n",
       "      <td>really</td>\n",
       "      <td>subject</td>\n",
       "      <td>question</td>\n",
       "      <td>people</td>\n",
       "      <td>time</td>\n",
       "      <td>post</td>\n",
       "      <td>thing</td>\n",
       "      <td>look</td>\n",
       "      <td>come</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word 0       Word 1   Word 2        Word 3  Word 4        Word 5  \\\n",
       "Topic 0      line      subject     post          host   world         reply   \n",
       "Topic 1      post         line     note          nntp    know         reply   \n",
       "Topic 2      know          use     good  distribution   write          line   \n",
       "Topic 3  possible  information     post         thank     day  distribution   \n",
       "Topic 4   problem          use     line           try  memory           bit   \n",
       "Topic 5    people        write     line          post     say           use   \n",
       "Topic 6      year          car      buy          make   close           use   \n",
       "Topic 7     thing       people    great          post   write         think   \n",
       "Topic 8       use         line   window          help     run           car   \n",
       "Topic 9     think        write  article          know    line           say   \n",
       "\n",
       "          Word 6   Word 7    Word 8        Word 9  Word 10 Word 11    Word 12  \\\n",
       "Topic 0     nntp   course   article         write     fact    note      right   \n",
       "Topic 1      use  include      hard  organization    thank   write  available   \n",
       "Topic 2     file      ask   include          come      old   thing       post   \n",
       "Topic 3     nntp  subject      just       article  include   major       need   \n",
       "Topic 4      say    think     write      computer      bad    work      thank   \n",
       "Topic 5  article    think      time           way     hand   agree       want   \n",
       "Topic 6      end      new       ask       include  summary     old       base   \n",
       "Topic 7      say      use      base        course      man    time      point   \n",
       "Topic 8     post     know   subject          need     look    nntp  available   \n",
       "Topic 9   really  subject  question        people     time    post      thing   \n",
       "\n",
       "             Word 13  Word 14  \n",
       "Topic 0         come     need  \n",
       "Topic 1          end  subject  \n",
       "Topic 2        thank  subject  \n",
       "Topic 3         year     host  \n",
       "Topic 4  information      run  \n",
       "Topic 5        right      let  \n",
       "Topic 6        thing  service  \n",
       "Topic 7      service  article  \n",
       "Topic 8        write   number  \n",
       "Topic 9         look     come  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show top n keywords for each topic\n",
    "def show_topics(vectorizer=vectorizer, lda_model=lda_model, n_words=20):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return topic_keywords\n",
    "\n",
    "topic_keywords = show_topics(vectorizer=vectorizer, lda_model=best_lda_model, n_words=15)        \n",
    "\n",
    "# Topic - Keywords Dataframe\n",
    "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
    "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = list(map(lambda x : int(x[3:]), list(df_document_topic[df_document_topic['dominant_topic']==4].index)))\n",
    "data_to_summarize = [data[i] for i in ids]\n",
    "len(data_to_summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096e3e230b3643718e9ab70fa15eb89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1300.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7dffd1e686423fb5211681ae0c03e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34503a10c004e1a8e6ffc468ac1f870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't reach server at 'https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-large-cnn/modelcard.json' to download model card file.\n",
      "Creating an empty model card.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99e21763409456d8d28dcb9e5e7c925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1625270765.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Apple co-founder Steve Jobs died,'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "def run_summary(gpt2_input):\n",
    "    summarizer = pipeline(\"summarization\")\n",
    "    return summarizer(gpt2_input, max_length = 10)\n",
    "test = \"\"\"\n",
    "Steve Jobs died years ago. But for devoted fans of the iconic Apple co-founder, it seems like just yesterday that Jobs stepped away from his role as Apple’s chief executive to seek treatment for the rare pancreatic cancer that would eventually kill him. But that begs the question: When did Steve Jobs die? And what were his last words?\n",
    "\n",
    "Read on to get all the details on Jobs’ untimely death, what he regretted about the choices he made during his life, and what his sister said were Steve Jobs’ last words.\n",
    "Steve Jobs developed a rare form of pancreatic cancer\n",
    "Steve Jobs opens the Apple Worldwide Developers conference in 2005\n",
    "\n",
    "Steve Jobs opened the Apple Worldwide Developers conference in 2005. | David Paul Morris/ Getty Images\n",
    "\n",
    "WebMD reports that if Steve Jobs had developed the most common form of pancreatic cancer, adenocarcinoma, he would likely have died soon after his 2003 diagnosis. Instead, he had an unusual form of pancreatic cancer known as a neuroendocrine tumor or islet cell carcinoma, which typically has a much better prognosis. Islet cells — the hormone-producing cells of the pancreas — develop cancers that are highly treatable and often curable. In 2004, Jobs underwent surgery to remove the tumor.\n",
    "\n",
    "Jobs is said to have undergone a Whipple procedure. That usually involves removing the head of the pancreas, part of the bile duct, the gallbladder, and the first part of the small intestine. Years later, in 2009, he received a liver transplant. That would have meant that cancer had spread to his liver. However, cancer can recur even after the transplant. And because the patient is on immune-suppressing anti-rejection drugs, there’s little that doctors can do. That’s what happened to Steve Jobs.\n",
    "He regretted his treatment decisions\n",
    "\n",
    "The Telegraph reports that Steve Jobs told his biographer that he regretted spending time trying to treat his cancer with alternative medicine. Jobs delayed operations and chemotherapy for nine months after his diagnosis in 2003 to try to treat his cancer without surgery. Biographer Walter Isaacson explained, “I think he felt: if you ignore something you don’t want to exist, you can have magical thinking. It had worked for him in the past. He would regret it.”\n",
    "\n",
    "Jobs’ wife, Laurene Powell, told Isaacson, “The big thing was he really was not ready to open his body. It’s hard to push someone to do that.” When Jobs did agree to traditional treatment, he had his DNA sequenced at the cost of $100,000. That enabled doctors to specifically target treatment to the particular molecular pathways that were defective in his body. But eventually, surgery revealed that cancer had spread beyond the pancreas to his liver.\n",
    "But the tumor could have spread even with earlier treatment\n",
    "Steve Jobs introduces the iPad 2\n",
    "\n",
    "Steve Jobs waves to the crowd. | Justin Sullivan/ Getty Images\n",
    "\n",
    "Steve Jobs might have regretted the decision to try acupuncture, a vegan diet, herbs, and juices before operating on his cancer. But The New York Times notes that it’s impossible to know whether that would have stopped his cancer from eventually killing him. Dean Ornish, one of Jobs’ doctors, told the Times, “No one can say whether or not having surgery earlier would have made any difference because of the possibility of micrometastases.”\n",
    "\n",
    "Micrometastases are tiny cancers that form in various organs when a tumor starts to spread around the body. The Times notes, “Dr. Ornish’s comment means that in theory, Mr. Jobs’ tumor could already have spread invisibly to his liver by the time it was first diagnosed. If it had, operating earlier probably would not have made a difference.” Another doctor explained that among patients with this kind of tumor, “when they are first found on a scan, about 60 percent of the time it’s already metastasized to the liver.”\n",
    "When did Steve Jobs die?\n",
    "\n",
    "Harvard Health reports that Steve Jobs died on October 5, 2011, “almost exactly eight years after his cancer was discovered incidentally on a CT scan of his kidneys (the pancreas is near the left kidney).” Jobs got the CT scan at the recommendation of his urologist, who was concerned about kidney stones he’d had several years earlier. Jobs’ liver transplant didn’t preclude his cancer from recurring. His liver was full of cancer when doctors removed it. That means that cancer had likely already spread outside the pancreas and liver at the time of the transplant.\n",
    "\n",
    "When Steve Jobs died on October 5, 2011, he was just 56 years old. He had taken medical leave from Apple starting in January that year, CNN reports. And he stepped down as Apple’s chief executive in August 2011, saying he could “no longer meet (his) duties and expectations.” Jobs was survived by his wife of 20 years, Laurene, and four children, including one — Lisa Brennan-Jobs — from a prior relationship.\n",
    "\"\"\"\n",
    "run_summary(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
